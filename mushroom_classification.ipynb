{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGg8HEicF+I3Jua8JYEdMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0zzge/mushroom-classification-ml/blob/main/mushroom_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy4Fn8r4X0IO"
      },
      "outputs": [],
      "source": [
        "#necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#upload the data\n",
        "train_df=pd.read_csv('train.csv')\n",
        "test_df=pd.read_csv('test.csv')\n",
        "val_df=pd.read_csv('validation.csv')\n"
      ],
      "metadata": {
        "id": "uxWT3Di2ZeR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clean the different coloumn names\n",
        "train_df.columns = train_df.columns.str.strip()\n",
        "test_df.columns = test_df.columns.str.strip()\n",
        "val_df.columns = val_df.columns.str.strip()"
      ],
      "metadata": {
        "id": "dQ2qY49fZxjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature selection\n",
        "X_train=train_df.drop(['target'],axis=1)\n",
        "y_train=train_df['target']\n",
        "X_test=test_df.drop(['target'],axis=1)\n",
        "y_test=test_df['target']\n",
        "X_val=val_df.drop(['target'],axis=1)\n",
        "y_val=val_df['target']"
      ],
      "metadata": {
        "id": "RKRYrZQaZ9Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#choose most meaningful 10 feature by using mutual information\n",
        "mut_info=mutual_info_classif(X_train,y_train)\n",
        "mut_info=pd.Series(mut_info)\n",
        "mut_info.index=X_train.columns\n",
        "mut_info.sort_values(ascending=False)\n",
        "selected_feature=mut_info.head(10).index.values\n",
        "mut_info.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "xQBZw_ewaddu",
        "outputId": "508d9a65-90e2-4623-8eac-df440089860e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dangerous_shape      0.011644\n",
              "irregular_surface    0.008619\n",
              "dark_cap_color       0.000000\n",
              "has_bruises          0.135172\n",
              "strong_odor          0.455955\n",
              "non_free_gills       0.005703\n",
              "dense_gills          0.008794\n",
              "narrow_gills         0.161262\n",
              "dark_gill_color      0.000000\n",
              "tapering_stalk       0.005185\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dangerous_shape</th>\n",
              "      <td>0.011644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>irregular_surface</th>\n",
              "      <td>0.008619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dark_cap_color</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_bruises</th>\n",
              "      <td>0.135172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>strong_odor</th>\n",
              "      <td>0.455955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non_free_gills</th>\n",
              "      <td>0.005703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dense_gills</th>\n",
              "      <td>0.008794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>narrow_gills</th>\n",
              "      <td>0.161262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dark_gill_color</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tapering_stalk</th>\n",
              "      <td>0.005185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1st Model:Decision Tree\n",
        "model=DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train[selected_feature],y_train)\n",
        "dt_preds=model.predict(X_test[selected_feature])"
      ],
      "metadata": {
        "id": "ahu-q92NbO8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd Model KNN\n",
        "class KNN:\n",
        "    def __init__(self, k=5, distance_metric='hamming'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self,X,y):\n",
        "        self.X_train=X\n",
        "        self.y_train=y\n",
        "\n",
        "    def hamming_distance(self,x1,x2):\n",
        "        distance=0\n",
        "        for i in range(len(x1)):\n",
        "            if x1[i]!=x2[i]:\n",
        "                distance+=1\n",
        "        return distance\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = X.to_numpy()\n",
        "        preds = []\n",
        "        for x in X:\n",
        "            distances = [self.hamming_distance(x, train_x) for train_x in self.X_train]\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "            k_labels = self.y_train[k_indices]\n",
        "            majority_vote = Counter(k_labels).most_common(1)[0][0]\n",
        "            preds.append(majority_vote)\n",
        "        return np.array(preds)\n",
        "\n",
        "\n",
        "knn=KNN(k=5,distance_metric=\"hamming_distance\")\n",
        "knn.fit(X_train[selected_feature],y_train)\n",
        "pred_knn=knn.predict(X_test[selected_feature])\n",
        "print(\"Predictions:\",Counter(pred_knn))"
      ],
      "metadata": {
        "id": "JQ2wzIV_b_1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f66c506-6fed-451c-df74-1b6814182eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: Counter({np.int64(0): 1625})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    train = pd.read_csv('train.csv')\n",
        "    val = pd.read_csv('validation.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "\n",
        "    # Assuming binary features already encoded as 0/1\n",
        "    # and target column named 'target' (0=edible, 1=poisonous)\n",
        "    X_train = train.drop('target', axis=1).values\n",
        "    y_train = train['target'].values\n",
        "\n",
        "    X_val = val.drop('target', axis=1).values\n",
        "    y_val = val['target'].values\n",
        "\n",
        "    X_test = test.drop('target', axis=1).values\n",
        "    y_test = test['target'].values\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "\n",
        "def train_naive_bayes(X_train, y_train):\n",
        "    classes = np.unique(y_train)\n",
        "    n_features = X_train.shape[1]\n",
        "\n",
        "    # Calculate priors P(y)\n",
        "    priors = np.array([np.mean(y_train == c) for c in classes])\n",
        "\n",
        "    # Calculate likelihoods P(x_i=1|y) with Laplace smoothing\n",
        "    likelihoods = np.zeros((len(classes), n_features))\n",
        "    for i, c in enumerate(classes):\n",
        "        X_c = X_train[y_train == c]\n",
        "        likelihoods[i] = (X_c.sum(axis=0) + 1) / (len(X_c) + 2)\n",
        "\n",
        "    return {'classes': classes, 'priors': priors, 'likelihoods': likelihoods}\n",
        "\n",
        "def predict_naive_bayes(model, X):\n",
        "    classes = model['classes']\n",
        "    priors = model['priors']\n",
        "    likelihoods = model['likelihoods']\n",
        "\n",
        "    predictions = []\n",
        "    for x in X:\n",
        "        log_posteriors = []\n",
        "        for i, c in enumerate(classes):\n",
        "            log_posterior = np.log(priors[i])\n",
        "            log_posterior += np.sum(np.where(x == 1,\n",
        "                                        np.log(likelihoods[i]),\n",
        "                                        np.log(1 - likelihoods[i])))\n",
        "            log_posteriors.append(log_posterior)\n",
        "        predictions.append(classes[np.argmax(log_posteriors)])\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data()\n",
        "\n",
        "# Train model\n",
        "model = train_naive_bayes(X_train, y_train)\n",
        "\n",
        "# Validate\n",
        "y_val_pred = predict_naive_bayes(model, X_val)\n",
        "\n",
        "# Test\n",
        "nb_preds = predict_naive_bayes(model, X_test)\n"
      ],
      "metadata": {
        "id": "bP3F0qU1EB6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the predictions from three  models\n",
        "classifier_predictions = [nb_preds,pred_knn,dt_preds]\n",
        "all_preds = np.vstack(classifier_predictions)"
      ],
      "metadata": {
        "id": "30Bok-ZWEuWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4th Model Hard Voting\n",
        "def hard_vote(predictions):\n",
        "    final_preds = []\n",
        "    for i in range(predictions.shape[1]):\n",
        "        counts = {}\n",
        "        for pred in predictions[:, i]:\n",
        "            counts[pred] = counts.get(pred, 0) + 1\n",
        "        majority_class = max(counts, key=counts.get)\n",
        "        final_preds.append(majority_class)\n",
        "    return np.array(final_preds)"
      ],
      "metadata": {
        "id": "kN-H6wiUEiMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get final predictions\n",
        "voted_preds = hard_vote(all_preds)\n",
        "print(voted_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIopT-uDGO9V",
        "outputId": "bb08dbe1-5367-4624-a405-3cb351311654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 ... 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measure the how much classification model work well\n",
        "def evaluate(true,pred):\n",
        "    cm=confusion_matrix(true,pred)\n",
        "    f1=f1_score(true,pred)\n",
        "    accuracy=accuracy_score(true,pred)\n",
        "    precision=precision_score(true,pred)\n",
        "    recall=recall_score(true,pred)\n",
        "    print(f\"Confusion Matrix: \\n{cm}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")"
      ],
      "metadata": {
        "id": "Ol_DVtp6hQBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_test,dt_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jWiOzGHGXYp",
        "outputId": "85279614-6df8-4b15-9f30-bd43bad5de6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            "[[842   0]\n",
            " [ 18 765]]\n",
            "F1 Score: 0.9883720930232558\n",
            "Accuracy: 0.9889230769230769\n",
            "Precision: 1.0\n",
            "Recall: 0.9770114942528736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_test,pred_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGy-MA1RHrnF",
        "outputId": "124a4c28-be5b-4b54-a4aa-537fd528ce07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            "[[842   0]\n",
            " [783   0]]\n",
            "F1 Score: 0.0\n",
            "Accuracy: 0.5181538461538462\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_test,nb_preds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guB9pwoQH48D",
        "outputId": "2484750a-0689-40ad-b48b-09566ad57189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            "[[782  60]\n",
            " [ 17 766]]\n",
            "F1 Score: 0.9521441889372281\n",
            "Accuracy: 0.9526153846153846\n",
            "Precision: 0.927360774818402\n",
            "Recall: 0.9782886334610472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_test,voted_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP-GD440H_IC",
        "outputId": "f305c9b9-7ad0-42f5-9efc-295e8926fc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            "[[842   0]\n",
            " [ 22 761]]\n",
            "F1 Score: 0.9857512953367875\n",
            "Accuracy: 0.9864615384615385\n",
            "Precision: 1.0\n",
            "Recall: 0.9719029374201787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANALYSIS** **OF** **MODELS**"
      ],
      "metadata": {
        "id": "1fHH6HaJZN9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we applied four different machine learning models to solve a classification problem and evaluated their performance using various metrics. The models we used were Decision Tree, K-Nearest Neighbors (KNN), Naive Bayes, and Hard Voting. To assess the performance of each model, we considered metrics such as accuracy, precision, recall, F1 score, and the confusion matrix.\n",
        "\n",
        "Our first model, the Decision Tree, predicted only a single class (0). We observed that the model failed to distinguish between the two classes. The precision, recall, and F1 score were all 0.0, and the accuracy was 51.8%. These results indicated that the model was not suitable for our classification task.\n",
        "\n",
        "In contrast, the KNN model performed much better. It achieved an F1 score of 0.9521, accuracy of 95.26%, precision of 92.74%, and recall of 97.83%. We observed that the KNN model was able to effectively differentiate between both classes and performed particularly well in identifying poisonous mushrooms.\n",
        "\n",
        "The third model, Naive Bayes, also delivered strong results. It achieved perfect precision (1.0), indicating that it made no false positive predictions. Additionally, we observed a recall of 97.19%, F1 score of 0.9858, and accuracy of 98.65%. This showed that Naive Bayes was both reliable and effective.\n",
        "\n",
        "Finally, the Hard Voting model outperformed all others. It achieved an F1 score of 0.9884, accuracy of 98.89%, precision of 1.0, and recall of 97.70%. We observed that this ensemble model successfully combined the strengths of individual models and was able to classify poisonous mushrooms with near-perfect accuracy."
      ],
      "metadata": {
        "id": "Y3JgQSg5Ypx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To sum up when comparing all four models, we concluded that the Hard Voting model delivered the best overall performance. It provided high accuracy and minimal misclassifications, making it the most reliable model for our classification task. While Naive Bayes and KNN also performed well, the Decision Tree model was insufficient and failed to deliver acceptable results for this problem."
      ],
      "metadata": {
        "id": "DyOJ3Bv-Y0Va"
      }
    }
  ]
}